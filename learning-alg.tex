\section{Algorithm for Learning of MMTs}
\label{sec:learning}

In this section, we present an algorithm for learning MMTs in then untimed
MAT of~\ref{sec:untimed-mat}, using the approximated Nerode equivalence
presented in Section~\ref{sec:approx}.
The learning algorithm follows the standard pattern for active automata learning
algorithms, such as $L^*$~\cite{Ang87}. It maintains
a set $U$ of lean behaviors, called {\em short prefixes}, which
represent states in the MMT to be constructed,
and an overapproximation of the Nerode equivalence,
parameterized by a set $V$ of input suffixes.
%% Each short prefix in $U$ is a feasible canonical untimed
%% behavior, which represents a state in the MMT to be constructed.
The learning algorithm iterates two phases: hypothesis construction and
hypothesis validation.
During hypothesis construction,
the approximation of the Nerode equivalence triggers the expansion of
$U$ and $V$ until two convergence conditions are satisfied that allow
a hypothesis automaton to be formed.
During hypothesis validation, the hypothesis automaton is submitted in an
equivalence query, and returned counterexamples are used to refine
the Nerode equivalence by expanding $V$.

\todobj{Say somewhere that we assume a fixed (un)timed language $S$.
  Make sure we make clear that it is the set of {\bf feasible} lean
behaviors of the SUL}

Let us introduce the two conditions for convergence of the construction phase.
For a lean behavior $\beta\in S$ and $\gamma \in \suffixbehs{S}{\beta}$, let
$\beta\compose{S}\gamma$ be the (unique) lean behavior $\beta'\cdot\suffmap{|\beta|}(\gamma)$ in $S$ with $\beta \sqsubseteq \beta'$.
Let $\feasibleinputs{\beta}{S}$ be the set of $i \in \extinputs$ such that
$\beta \compose{S} \simpleutlabel{i}{o} \in S$ for some $o$ (recall that the
last assignment of a lean behavior is always empty).
For $i \in \feasibleinputs{\beta}{S}$, let $\lambda(\beta,i)$ be the unique
output $o$ such that $\beta \compose{S} \simpleutlabel{i}{o} \in S$.
%% A set $V$ of generic untimed input words is {\em adequate} if it includes
%% $I \cup \set{\toevent{p}}$.
Let $U$ be a prefix-closed set of lean behaviors.
and let $V$ be an adequate set of input suffixes.
\begin{itemize}
\item
$U$ is {\em closed} wrt.\ $V$ if 
  for each $\beta \in U$ and
  $i \in \feasibleinputs{\beta}{S}$
%%   , which is either in $I$ or of form $\toevent{x_i}$ where $x_i$ is expirable after $\beta$ if
  there is a $\beta' \in U$ such that
  $\beta\compose{S}\simpleutlabel{i}{\lambda(\beta,i)} \equiv_{S,V} \beta'$.
\item
$U$ is {\em timer-consistent} wrt.\ $V$ if 
  for each $\beta \in U$ and
  $i \in \feasibleinputs{\beta}{S}$
  %% $i$, which is either in $I$ or
  %% of form $\toevent{x_i}$ for $x_i$ expirable after $\beta$,
  we have
  $\apprgetmemorable{S}{\beta\compose{S}\simpleutlabel{i}{\lambda(\beta,i)}}{V} \subseteq
  (\apprgetmemorable{S}{\beta}{V} \cup \set{x_{(|\beta|+1)}})$.
\end{itemize}
Closedness ensures that each transition in the MMT to be constructed has a target state. 
Timer-consistency states that each timer which is needed after such
a transition (i.e., a timer set during $\beta\compose{S}\simpleutlabel{i}{\lambda(\beta,i)}$)
is either a timer active after $\beta$ or is started by the last transition, thus
getting the name $x_{(|\beta|+1)}$.
Closedness and timer-consistency allow the construction of a hypothesis MMT.

\begin{definition}[Hypothesis automaton]
\label{def:hypo}
  Let $U$ be a non-empty prefix-closed set of lean behaviors,
  and $V$ an adequate set of input suffixes such that
  $U$ is closed and timer consistent wrt.\ $V$. Then the
{\em hypothesis automaton} $\hypoof UV$ is the MMT
$\hypoof UV = (I, O, Q, q_0, \vars, \delta, \lambda, \remap)$, where
\begin{itemize}
\item $Q = U$ and $q_0 = \emptyword$,
\item $\vars$ maps each location $\beta\in U$ to $\apprgetmemorable{S}{\beta}{V}$,
\item Let $\beta \in U$ and $i \in \feasibleinputs{\beta}{S}$. Then
  \begin{itemize}
    \item $\lambda(\beta,i)$ is
     the unique $o$ such that $\extend{\beta}{i}{o} \in S$. 
    \item $\delta(\beta,i)$ is is
        the unique $\beta' \in U$ such that there is an $f$ with
  $\extend{\beta}{i}{\lambda(\beta,i)} \equiv_{S,V}^f \beta'$.
      \item $\remap(\beta,i):\apprgetmemorable{S}{\beta'}{V} \mapsto (\apprgetmemorable{S}{\beta}{V} \cup \natplus)$ is defined as $f^{-1}$ on
        $\apprgetmemorable{S}{\beta'}{V}$, except that it maps
        $f(x_{(|\beta|+1)})$ to
        $\apprgetassignment{S}{\beta'}{V}(f(x_{(|\beta|+1)}))$
        if $f(x_{(|\beta|+1)}) \in \apprgetmemorable{S}{\beta'}{V}$.
  \end{itemize}
\item When $\beta \in U$ and $i$ is of form $\toevent{x_j}$ with
  $x_i \apprgetmemorable{S}{\beta}{V}$ but
  $\toevent{x_j} \not\in\feasibleinputs{\beta}{S}$, we let
  $\lambda(\beta,i) = \bot$, 
  $\delta(\beta,i) = \beta$, and let
  $\remap(\beta,i)$ be the identity mapping on $\apprgetmemorable{S}{\beta}{V}$.
\end{itemize}
\end{definition}
The last case (where  $\toevent{x_j} \not\in\feasibleinputs{\beta}{S}$)
constructs a transition that is not feasible,
but which must anyway be syntactically present, since $x_j$
may expire after some continuation if $\beta$ and is hence live.

{\bf Hypothesis construction}, performs membership queries in order
 to construct the sets of form $\apprsuffixbehs{S}{\beta}{V}$ and
 $\apprsuffixbehs{S}{\extend{\beta}{i}{\lambda(\beta,i)}}{V}$
 for $\beta \in U$ and $i \in \feasibleinputs{\beta}{S}$.
 Moreoever, the sets $U$ and $V$ are expanded if needed to construct
 a hypothesis automaton.

 More precisely,
membership queries are first performed
  for all untimed input words of form $\untimedinputword(\beta) \cdot i$
   for $\beta \in U$ and $i \in \extinputs$: this allows to determine
   $\feasibleinputs{\beta}{S}$ and $\lambda(\beta,i)$
   for $\beta \in U$ and $i \in \feasibleinputs{\beta}{S}$.
   Thereafter, membership queries are performed
  for all untimed input words of form $\untimedinputword(\beta) \cdot v$ and
  $\untimedinputword(\beta) \cdot i \cdot v$, where
  $\beta \in U$, $v \in V$, and
  $i \in \feasibleinputs{\beta}{S}$. Note that one need only consider
  $v$ in which timeouts from $\toevents$ concern timers in
  $\set{x_1, \ldots, x_{|\beta|}}$ (or in  $\set{x_1, \ldots, x_{(|\beta|+1)}}$
  for $\untimedinputword(\beta) \cdot i$).
  This allows to construct the sets of form $\apprsuffixbehs{S}{\beta}{V}$ and
  $\apprsuffixbehs{S}{(\extend{\beta}{i}{\lambda(\beta,i)})}{V}$
  for $\beta \in U$.
  It then allows to compute the approximated Nerode equivalence $\equiv_{S,V}$ on
  the set of lean behaviors of form $\beta$ and
  $\extend{\beta}{i}{\lambda(\beta,i)}$ with
  $\beta \in U$ and $i \in \feasibleinputs{\beta}{S}$.
  We then check whether $U$ and $V$ meet the convergence criteria.
  \begin{itemize}
    \item
  Whenever the set $U$ is not closed wrt.\ $V$, then it is extended:
if there is some $\beta \in U$ and $i$ in $\feasibleinputs{\beta}{S}$
for which there is no $\beta' \in U$ such that
$\extend{\beta}{i}{\lambda(\beta,i)} \equiv_{S,V} \beta'$, 
then $\extend{\beta}{i}{\lambda(\beta,i)}$ is added to $U$,
triggering new membership queries.
\item
  Whenever the set $U$ is not timer-consistent wrt.\ $V$, then $V$ is extended:
for timer $x_j$ in
$\apprgetmemorable{S}{\extend{\beta}{i}{\lambda(\beta,i)}}{V} \setminus (\apprgetmemorable{S}{\beta}{V} \cup \set{x_{(|\beta|+1)}})$, find a lean
suffix $\gamma$ in
$\apprsuffixbehs{S}{(\extend{\beta}{i}{\lambda(\beta,i)})}{V}$, whose last input
is $\toevent{x_j}$. This input is
obviously missing from $\apprsuffixbehs{S}{\beta}{V}$. But, by adding
the concatenation of $i$ with $\untimedinputword(\gamma)$ (where
timers are  appropriately renamed), the input $\toevent{x_j}$
will also appear in $\apprgetmemorable{S}{\beta}{V}$.
This extension of $V$ will subsequently trigger new membership queries.
\end{itemize}
When $U$ is closed and timer-consistent wrt.\ $V$, then
a hypothesis MMT $\hypoof UV$ is constructed and
validated by submitting it in an equivalence query.
If the query returns ``yes'', then
the learning is completed, and $\hypoof UV$ accepts $S$.
If the query returns a counterexample in the form of a lean behavior
$\alpha$ on which $\hypoof UV$ and $S$ disagree,
this is used to extend $V$ by a new input suffix $v$ (and its permutations),
such that
$U$ is no longer closed wrt.\ $V$.
\ifshort
The procedure for producing this $v$ from $\alpha$ is found in the
appendix.
\else
as follows.
We assume w.l.o.g.\ that no proper prefix of $\alpha$ is a counterexample. 
By the fact that $\alpha$ is a counterexample, we can find a lean
suffix $\gamma$ of $\alpha$, such that
$\beta\cdot \simpleutlabel{i}{o} \equiv_{S,V}^f \beta'$ but
$\gamma \in \suffixbehs{S}{(\extend{\beta}{i}{\lambda(\beta,i)})}
\smallnotiff \gamma \in \suffixbehs{S}{\beta'}$
for some $\beta,\beta' \in U$ such that 
$\beta\compose{S}\simpleutlabel{i}{o} \equiv_{S,V}^f \beta'$ is used to construct
the transition triggered by $i$ from $\beta$ in $\hypoof UV$.
To se this, let $\alpha = \utlabel{i_1}{o_1}{\rho_1} \cdots \utlabel{i_n}{o_n}{\rho_n}$, and for $j = 0 , \ldots, n$, define
a lean behavior $\beta_j$ and a $\beta_j$-suffix as follows.
\begin{itemize}
\item $\beta_0 = \emptyword$, and
%%   , $f_0$ is arbitrary, and 
  $\gamma_0$ is obtained by making $\alpha$ a lean suffix (i.e.,
  renaming each timer $x_l$ to $y_l$).
\item
  Let $\gamma_{j-1}$ be of form
  $\utlabel{\hat{i_j}}{\hat{o_j}}{\hat{\rho_j}} \cdot \gamma_{j-1}'$,
  let $\beta_j$ be $\lambda(\beta_{j-1},\hat{i_j})$,
  let $f_j$ be the mapping used to establish
  $\beta_{j-1}\compose{S}\simpleutlabel{\hat{i_j}}{\hat{o_j}} \equiv_{S,V}^{f_j} \beta_{j}$
  in the construction of $\hypoof UV$,
  and let $\gamma_j$ be obtained from $\gamma_{j-1}'$ by
  (i) applying $f_j$ to timers in $\set{x_1, \ldots , x_{\beta_{j-1}}}$,
  (ii) replacing $y_1$ by $f_j(x_{\beta_{j-1}+1})$, and
  (ii) replacing each $y_l$ by $y_{l-1}$.
\end{itemize}
The result is that
$\beta_0 \ldots \beta_n$ is the sequence of states 
visited when $\hypoof UV$ processes $\alpha$, and
$\gamma_j$ is lean suffix that can be composed with $\beta_j$,
which corresponds to a suffix of $\alpha$.
%% Let $\gamma_j$ be the suffix
%% $\utlabel{i_{j+1}}{o_{j+1}}{\rho_{j+1}} \cdots \utlabel{i_n}{o_n}{\rho_n}$
%% of $\alpha$ of length $n-j$. 
By the fact that $\alpha$ is a counterexample, we have
$\gamma_0 \in\suffixbehs{S}{\beta_0} \smallnotiff \gamma_n \in\suffixbehs{S}{\beta_n}$ (since $\gamma_n$ is the empty sequence), which implies that
$\gamma_{j-1} \in\suffixbehs{S}{\beta_{j-1}}
\smallnotiff
\gamma_{j} \in\suffixbehs{S}{\beta_{j}}$
for some $j$;
we can then take $\beta_{j-1}$ as $\beta$ and $\beta_j$ as $\beta'$, and
$\gamma$ as $\gamma_j$.
This means that $\gamma$ is a new separating suffix, and that $V$ should be
extended with $\untimedinputword(\gamma)$.
After adding $v$ (and its permutations) to $V$, $U$ is no longer closed
wrt.\ $V$,
\fi
The algorithm can then resume a next round of
hypothesis construction, which will eventually generate a new hypothesis, etc.

The algorithm enjoys the following properties, are analogous
to properties by, e.g., $L^*$~\cite{Ang87}.
The additional complexity caused by timers is analogous
to the additional complexity caused by registers in learning of register
automata~\cite{HowarSJC12,CasselHJS16}.

\begin{theorem}
  \label{thm:alg:termination}
  Given an MMT $\M$ whose canonical form has $n$ states, each of which has
  at most $r$ active timers, the
  procedure of this section terminates and produces an equivalent MMT in
  canonical form, using a number of queries that is at most
  polynomial in $n$ and doubly exponential in $r$.
\end{theorem}

At termination the hypothesis is correct, by definition of equivalence query.
During the construction, $U$ will never contain two elements that are
equivalent wrp. $\M$.
Since each round of hypothesis construction and validation adds at least one
word to $U$, there can be at most $n$ equivalence queries.

Let us analyze the number of queries that may be required in the worst case
to learn an MMT whose canonical form has $n$ states and at most $r$ active
timers in any state.
\begin{itemize}
\item
  Hypothesis construction may need $n\cdot(|I|+r+1)\cdot |V|^r$
  membership queries in total. The factor $|V|^r$ arises as the number of
  permutations of prefix-timers in each suffix.
\item
  Processing a counterexample may need $\log(m)$ membership queries,
  using binary search, where $m$ is the length of the counterexample.
\item
  Each equivalence query will result in refuting an equivalence of form
  $\beta\cdot \simpleutlabel{i}{o} \equiv_{S,V}^f \beta'$, and extending
   $V$. There are at most
  $r !$ possible permutations $f$ for each $\beta\cdot \simpleutlabel{i}{o}$,
  implying at most $n \cdot r!$ equivalence queries.
\item Since each equivalence query adds at most $r!$ permutations
 to $V$, this means that $|V| \leq n\cdot(r!)^2$ when the algorithm finishes,
\end{itemize}


%% implying that in total, at most $n^2|I|$ membership queries
%% will be performed during hypothesis construction.
%% During hypothesis
%% validation, at most $2\log(m)$ membership queries need be performed
%% (in addition to the equivalence query), where
%% $m$ is the length of the largest counterexample word returned.

